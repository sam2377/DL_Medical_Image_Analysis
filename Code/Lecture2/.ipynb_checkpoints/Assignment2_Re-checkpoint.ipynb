{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "* In this assignment, we will train a CNN Autoencoder with DX, dental and all-MIAS dataset.\n",
    "* The result should be compared with conventional denoised methods.\n",
    "* Comparisons are based on structural similarity index measure(SSIM) and peak signal to noise ratio (PSNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "Use the following lines to import any needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may reference to these links below\n",
    "# Tensorflow api: https://www.tensorflow.org/api_docs/python/tf/keras\n",
    "# Skimage api: https://scikit-image.org/docs/stable/api/api.html\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "# from skimage.metrics import structural_similarity as ssim\n",
    "# from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "# from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(array, random = False):\n",
    "    \n",
    "    \"\"\"Show 10 2-D image from 3-D array \n",
    "\n",
    "    Parameters:\n",
    "        array(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W]\n",
    "        random(bool): Flag determines show image following by index sequence or not.\n",
    "\n",
    "    \"\"\"\n",
    "    n = 10\n",
    "    if random == True:\n",
    "        indices = np.random.randint(len(array), size=n)\n",
    "    else:\n",
    "        indices = np.arange(n)\n",
    "    images = array[indices, :]\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15,5))\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            image = images[i*5+j, :, :]\n",
    "            axes[i, j].set_title(\"Index = {}\".format(indices[i*5+j]))\n",
    "            axes[i, j].axis(\"off\")\n",
    "            axes[i, j].imshow(images[i*5+j].reshape(array.shape[1], array.shape[2]), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pgm(filename):\n",
    "    \n",
    "    \"\"\"Return image data from a raw PGM file as numpy array.\n",
    "    Format specification: \n",
    "        http://netpbm.sourceforge.net/doc/pgm.html\n",
    "        https://zh.wikipedia.org/wiki/PBM%E6%A0%BC%E5%BC%8F\n",
    "    \n",
    "    Parameters: \n",
    "        filename: Specify filename\n",
    "    Returns:\n",
    "        np.ndarray[int, int]): 2-D Image array expected each of shape [H, W] \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        buffer = f.read()\n",
    "    try:\n",
    "        header, width, height, maxval = re.search(\n",
    "            b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "#         print('Header:{}\\nWidth:{}\\nHeight:{}\\nMaxval:{}'.format(header, width, height, maxval))\n",
    "#         print('len {}'.format(len(header)))\n",
    "    except AttributeError:\n",
    "        raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n",
    "    return np.frombuffer(buffer,\n",
    "                            dtype='u1',\n",
    "                            count=int(width) * int(height),\n",
    "                            offset=len(header)\n",
    "                            ).reshape((int(height), int(width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dental(folder=\"./data/dental/\"):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder), key=lambda x : int(x.split('.')[0])):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "def read_mini_mias(folder=\"./data/all-mias/\"):\n",
    "    images = np.zeros((322, 1024, 1024))\n",
    "    i = 0\n",
    "    for dirName, subdirList, fileList in os.walk(folder):\n",
    "        for fname in fileList:\n",
    "            if fname.endswith(\".pgm\"):\n",
    "                images[i] = read_pgm(folder + fname)\n",
    "                i += 1\n",
    "    return images\n",
    "\n",
    "def read_dx(folder=\"data/DX/\"):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder), key=lambda x : int(x.split('.')[0])):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "def load_datasets(img_width=256, img_height=256):\n",
    "    \n",
    "    \"\"\"Load datasets with image resize\n",
    "\n",
    "    Parameters:\n",
    "        img_width(int): Resize image with img_width\n",
    "        img_height(int): Resize image with img_height\n",
    "    Returns:\n",
    "        mias_images(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W] \n",
    "        dx_images(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W] \n",
    "        dental_images(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W] \n",
    "    \n",
    "    Example::\n",
    "        >>> mias_images, dx_images, dental_images = load_datasets(img_width, img_height)\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Read mias dataset\n",
    "    raw_mias = read_mini_mias()\n",
    "\n",
    "    mias_images = np.zeros((raw_mias.shape[0], img_width, img_height))\n",
    "    for i in range(raw_mias.shape[0]):\n",
    "        mias_images[i] = cv2.resize(raw_mias[i], dsize=(img_width, img_height),\n",
    "                                    interpolation=cv2.INTER_AREA)\n",
    "    # Read dental dataset\n",
    "    raw_dental = read_dental()  \n",
    "    dental_images = np.zeros((raw_dental.shape[0], img_width, img_width))\n",
    "    for i in range(raw_dental.shape[0]):\n",
    "        dental_images[i] = cv2.resize(raw_dental[i], dsize=(img_width, img_height),\n",
    "                                      interpolation=cv2.INTER_AREA)\n",
    "    # Read DX dataset\n",
    "    raw_dx = read_dx()\n",
    "    dx_images = np.zeros((raw_dx.shape[0], img_width, img_width))\n",
    "    for i in range(raw_dx.shape[0]):\n",
    "        dx_images[i] = cv2.resize(raw_dx[i], dsize=(img_width, img_height),\n",
    "                                  interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return mias_images, dx_images, dental_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(array):\n",
    " \n",
    "    \"\"\"Adds random Guassian noise to each image in the supplied array.\n",
    "\n",
    "    Parameters:\n",
    "        array(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W]\n",
    "    Returns:\n",
    "        noisy_array(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W] \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    noise_factor = 0.1\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(mias_images, dx_images, dental_images, train_split=0.9, img_height=256, img_width=256, seed=0):\n",
    "    \n",
    "    \"\"\"Combine datasets and split data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        mias_images(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W]\n",
    "        dx_images(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W]\n",
    "        dental_images(np.ndarray[int, int, int]): 3-D Image array expected each of shape [N, H, W]\n",
    "        train_split(float): Proportion of the dataset to include in the training sets\n",
    "        img_height(int): Height of image\n",
    "        img_width(int): Width of image\n",
    "        seed(int): Specify fixed seed number\n",
    "        \n",
    "    Returns:\n",
    "        imageset_train(np.ndarray[int, int, int, int]): Training sets, shape [N, H, W, C]\n",
    "        imageset_test(np.ndarray[int, int, int, int]): Testing sets, shape [N, H, W, C]\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(mias_images)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(dx_images)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(dental_images)   \n",
    "    \n",
    "    imageset_train = mias_images[:int(mias_images.shape[0] * train_split)]\n",
    "    imageset_train = np.append(imageset_train, dx_images[:int(dx_images.shape[0] * train_split)], axis=0)\n",
    "    imageset_train = np.append(imageset_train, dental_images[:int(dental_images.shape[0] * train_split)], axis=0)\n",
    "    \n",
    "    imageset_test = mias_images[int(mias_images.shape[0] * train_split):]\n",
    "    imageset_test = np.append(imageset_test, dx_images[int(dx_images.shape[0] * train_split):], axis=0)\n",
    "    imageset_test = np.append(imageset_test, dental_images[int(dental_images.shape[0] * train_split):], axis=0)\n",
    "    \n",
    "    imageset_train = imageset_train.reshape(imageset_train.shape[0], img_height, img_width, 1)\n",
    "    imageset_test = imageset_test.reshape(imageset_test.shape[0], img_height, img_width, 1)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(imageset_train)\n",
    "    \n",
    "    return imageset_train, imageset_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
