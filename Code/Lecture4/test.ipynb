{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import skimage.color as color\n",
    "import random as r\n",
    "import math\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, concatenate, UpSampling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original img size is 240*240\n",
    "image_size = 192\n",
    "smooth = 1 \n",
    "num_of_aug = 1\n",
    "num_epoch = 10\n",
    "pul_seq = 'Flair'\n",
    "sharp = False       # sharpen filter\n",
    "\n",
    "label_num = 5   # 1 = necrosis, 2 = tumor core, 4 = ET, 5 = complete tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(src, mask, label=False, image_size=192):\n",
    "    files = glob.glob(src + mask, recursive=True)\n",
    "    imgs = []\n",
    "    print('Processing---', mask)\n",
    "    for file in files:\n",
    "        img = io.imread(file, plugin='simpleitk')\n",
    "        if label:\n",
    "            if label_num == 5:\n",
    "                img[img != 0] = 1       #Region 1 => 1+2+3+4 complete tumor\n",
    "            if label_num == 1:\n",
    "                img[img != 1] = 0       #only left necrosis\n",
    "            if label_num == 2:\n",
    "                img[img == 2] = 0       #turn edema to 0\n",
    "                img[img != 0] = 1       #only keep necrosis, ET, NET = Tumor core\n",
    "            if label_num == 4:\n",
    "                img[img != 4] = 0       #only left ET\n",
    "                img[img == 4] = 1\n",
    "            img = np.asarray(img, dtype = np.int32)\n",
    "            img = img[50:90]\n",
    "            for s in img:\n",
    "                s = cv2.resize(s, (image_size, image_size), interpolation = cv2.INTER_NEAREST)\n",
    "                imgs.append(s)\n",
    "        else:\n",
    "            img = ((img-np.min(img)) / np.max(img)) * 2 - 1\n",
    "            img = np.asarray(img, dtype = np.float32)\n",
    "            img = img[50:90]\n",
    "            for s in img:\n",
    "                s = cv2.resize(s, (image_size, image_size), interpolation = cv2.INTER_LINEAR)\n",
    "                imgs.append(s)\n",
    "#         for slice in range(50,90):     #choose the slice range\n",
    "#             s = img[slice,:,:]\n",
    "#             img_t = cv2.resize(s, (192, 192), interpolation = cv2.INTER_LINEAR)\n",
    "#             img_t = np.expand_dims(img_t, axis=2)\n",
    "#             img_t = np.expand_dims(img_t, axis=0)\n",
    "#             img_g = augmentation(img_t, num_of_aug)\n",
    "#             for n in range(img_g.shape[0]):\n",
    "#                 imgs.append(img_g[n,:,:,:])\n",
    "#         break\n",
    "    name = './data/sample_{}_{}_mask'.format(pul_seq, image_size) if label else './data/sample_{}_{}_image'.format(pul_seq, image_size)\n",
    "    np.save(name, np.array(imgs).astype('float32'))  # save at home\n",
    "    print('Saved', len(files), 'to', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(scans, n):          #input img must be rank 4 \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,   \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=25,\n",
    "        zoom_range=False)\n",
    "    i = 0\n",
    "    scans_g = scans.copy()\n",
    "    for batch in datagen.flow(scans, batch_size=1, seed=1000): \n",
    "        scans_g = np.vstack([scans_g,batch])\n",
    "        i += 1\n",
    "        if i == n:\n",
    "            break\n",
    "\n",
    "    return scans_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(array, array2, random = False):\n",
    "    n = 5\n",
    "    if random == True:\n",
    "        indices = np.random.randint(len(array), size=n)\n",
    "        print('Show Random {} images and masks'.format(n))\n",
    "    else:\n",
    "        indices = np.arange(n)\n",
    "        print('Show First {} images and masks'.format(n))\n",
    "    images = array[indices, :]\n",
    "    masks = array2[indices, :]\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15,5))\n",
    "    for i in range(5):\n",
    "        image = images[i, :, :]\n",
    "        mask = masks[i, :, :]\n",
    "        axes[0, i].set_title(\"Image Index = {}\".format(indices[i]))\n",
    "        axes[0, i].axis(\"off\")\n",
    "        axes[0, i].imshow(image, cmap='gray')\n",
    "        axes[1, i].set_title(\"Mask Index = {}\".format(indices[i]))\n",
    "        axes[1, i].axis(\"off\")\n",
    "        axes[1, i].imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size=192):\n",
    "    inputs = Input((image_size, image_size, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4= Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5= Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis = -1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6= Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(up6), conv3], axis = -1)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7= Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(up7), conv2], axis = -1)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8= Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(up8), conv1], axis = -1)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9= Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    \n",
    "    conv10= Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create_data('./BRATS2015_Training/HGG/', '**/*{}*.mha'.format(pul_seq), label=False, image_size=192)\n",
    "# create_data('./BRATS2015_Training/HGG/', '**/*OT*.mha', label=True, image_size=192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('./data/sample_{}_{}_image.npy'.format(pul_seq, image_size))\n",
    "y = np.load('./data/sample_{}_{}_mask.npy'.format(pul_seq, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x, y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x, y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = build_model(image_size)\n",
    "x_train = np.expand_dims(x, -1)\n",
    "y_train = np.expand_dims(y, -1)\n",
    "# history = model.fit(x_train, y_train, batch_size=16, validation_split=0.2 ,epochs = num_epoch ,verbose=1, shuffle=True)\n",
    "# model.save_weights('weights_{}_{}.h5'.format(image_size,num_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(range(num_epoch), loss, marker='.', label='loss(training data)')\n",
    "plt.plot(range(num_epoch), val_loss, marker='.', label='val_loss(evaluationdata)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = build_model(image_size)\n",
    "model.load_weights(\"weights_192_10.h5\")\n",
    "pred = model.predict(x_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.squeeze(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(np.squeeze(pred), np.squeeze(y), False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
